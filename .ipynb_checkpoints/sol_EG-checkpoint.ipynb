{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "import musicbrainzngs\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import csv\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Models\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# PCA and k-fold validation\n",
    "# from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_file = '../musicrec-data/train.csv'\n",
    "test_file  = '../musicrec-data/test.csv'\n",
    "# change this to reflect different solutions\n",
    "soln_file  = 'user_median.csv'\n",
    "\n",
    "# Load the training data.\n",
    "train_data = {}\n",
    "Y_actual = {} # for testing\n",
    "id = 1\n",
    "with open(train_file, 'r') as train_fh:\n",
    "    train_csv = csv.reader(train_fh, delimiter=',', quotechar='\"')\n",
    "    next(train_csv, None)\n",
    "    for row in train_csv:\n",
    "        user   = row[0]\n",
    "        artist = row[1]\n",
    "        plays  = int(row[2])\n",
    "        Y_actual[id] = plays\n",
    "        id += 1\n",
    "        if not user in train_data:\n",
    "            train_data[user] = {}\n",
    "        \n",
    "        train_data[user][artist] = plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soln_file = 'global_median.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# globalmedian.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global median: 118.0\n"
     ]
    }
   ],
   "source": [
    "# Predict via the median number of plays.\n",
    "\n",
    "# Compute the global median.\n",
    "plays_array = []\n",
    "for user, user_data in train_data.items():\n",
    "    for artist, plays in user_data.items():\n",
    "        plays_array.append(plays)\n",
    "global_median = np.median(np.array(plays_array))\n",
    "print(\"global median:\", global_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write out test solutions.\n",
    "with open(test_file, 'r') as test_fh:\n",
    "    test_csv = csv.reader(test_fh, delimiter=',', quotechar='\"')\n",
    "    next(test_csv, None)\n",
    "\n",
    "    with open(soln_file, 'w') as soln_fh:\n",
    "        soln_csv = csv.writer(soln_fh,\n",
    "                              delimiter=',',\n",
    "                              quotechar='\"',\n",
    "                              quoting=csv.QUOTE_MINIMAL)\n",
    "        soln_csv.writerow(['Id', 'plays'])\n",
    "\n",
    "        for row in test_csv:\n",
    "            id     = row[0]\n",
    "            user   = row[1]\n",
    "            artist = row[2]\n",
    "\n",
    "            soln_csv.writerow([id, global_median])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# usermedian.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict via the user-specific median.\n",
    "# If the user has no data, use the global median.\n",
    "\n",
    "# Compute the global median and per-user median.\n",
    "plays_array  = []\n",
    "user_medians = {}\n",
    "for user, user_data in train_data.items():\n",
    "    user_plays = []\n",
    "    for artist, plays in user_data.items():\n",
    "        plays_array.append(plays)\n",
    "        user_plays.append(plays)\n",
    "\n",
    "    user_medians[user] = np.median(np.array(user_plays))\n",
    "global_median = np.median(np.array(plays_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write out test solutions.\n",
    "Y_hat = {}\n",
    "line_id = 1\n",
    "with open(test_file, 'r') as test_fh:\n",
    "    test_csv = csv.reader(test_fh, delimiter=',', quotechar='\"')\n",
    "    next(test_csv, None)\n",
    "\n",
    "    with open(soln_file, 'w') as soln_fh:\n",
    "        soln_csv = csv.writer(soln_fh,\n",
    "                              delimiter=',',\n",
    "                              quotechar='\"',\n",
    "                              quoting=csv.QUOTE_MINIMAL)\n",
    "        soln_csv.writerow(['Id', 'plays'])\n",
    "\n",
    "        for row in test_csv:\n",
    "            id     = row[0]\n",
    "            user   = row[1]\n",
    "            artist = row[2]\n",
    "\n",
    "            if user in user_medians:\n",
    "                soln_csv.writerow([id, user_medians[user]])\n",
    "                Y_hat[line_id] = user_medians[user]\n",
    "            else:\n",
    "                print(\"User\", id, \"not in training data.\")\n",
    "                soln_csv.writerow([id, global_median])\n",
    "                Y_hat[line_id] = global_median\n",
    "            \n",
    "            line_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing around with musicbrainzngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# must set user agent before any requests are made\n",
    "musicbrainzngs.set_useragent(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist information, searching, and browsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:\t\tRadiohead\n",
      "rating:\t\t{'rating': '4.45', 'votes-count': '59'}\n",
      "release 0:\t{'status': 'Official', 'release-event-count': 1, 'title': 'Pablo Honey', 'country': 'XE', 'barcode': '077778140924', 'release-event-list': [{'date': '1993', 'area': {'sort-name': 'Europe', 'iso-3166-1-code-list': ['XE'], 'id': '89a675c2-3e37-3518-b83c-418bad59a85a', 'name': 'Europe'}}], 'packaging': 'Jewel Case', 'text-representation': {'language': 'eng', 'script': 'Latn'}, 'date': '1993', 'quality': 'normal', 'id': '06487940-c7d4-4af3-976d-0be796d686ce'}\n"
     ]
    }
   ],
   "source": [
    "musicbrainzngs.search_artists(\"radiohead\")\n",
    "#musicbrainzngs.search_recordings(\"bennie and the jets\")\n",
    "\n",
    "radiohead_id = \"a74b1b7f-71a5-4011-9441-d0b5e4122711\"\n",
    "radiohead_result = musicbrainzngs.get_artist_by_id(radiohead_id,includes=[\"releases\",\"ratings\"])\n",
    "radiohead_artist = radiohead_result[\"artist\"]\n",
    "\n",
    "print(\"name:\\t\\t%s\" % radiohead_artist[\"name\"])\n",
    "print(\"rating:\\t\\t%s\" % radiohead_artist[\"rating\"])\n",
    "print(\"release 0:\\t%s\" % radiohead_artist[\"release-list\"][0])\n",
    "\n",
    "# dictionary of recordings for radiohead\n",
    "# musicbrainzngs.browse_recordings(radiohead_id)\n",
    "\n",
    "# \"artist\" can include the following information:\n",
    "# recordings, releases, release-groups, works, various-artists,\n",
    "# discids, media, isrcs, aliases, annotation, area-rels, artist-rels,\n",
    "# label-rels, place-rels, event-rels, recording-rels, release-rels,\n",
    "# release-group-rels, series-rels, url-rels, work-rels, instrument-rels,\n",
    "# tags, user-tags, ratings, user-ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cover art information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'images': [{u'approved': True,\n",
       "   u'back': False,\n",
       "   u'comment': u'',\n",
       "   u'edit': 35299266,\n",
       "   u'front': True,\n",
       "   u'id': 11628918400,\n",
       "   u'image': u'http://coverartarchive.org/release/081e7033-5282-4bd7-9963-e64edf8c693a/11628918400.jpg',\n",
       "   u'thumbnails': {u'large': u'http://coverartarchive.org/release/081e7033-5282-4bd7-9963-e64edf8c693a/11628918400-500.jpg',\n",
       "    u'small': u'http://coverartarchive.org/release/081e7033-5282-4bd7-9963-e64edf8c693a/11628918400-250.jpg'},\n",
       "   u'types': [u'Front']}],\n",
       " u'release': u'https://musicbrainz.org/release/081e7033-5282-4bd7-9963-e64edf8c693a'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets the list of cover art associated with a release\n",
    "musicbrainzngs.get_image_list(\"081e7033-5282-4bd7-9963-e64edf8c693a\")\n",
    "\n",
    "# downloads the front cover art of a release\n",
    "# musicbrainzngs.get_image_front(\"081e7033-5282-4bd7-9963-e64edf8c693a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for k-fold cross validation using MAE (mean absolute error)\n",
    "def kfold(k, model, data):\n",
    "    kf = KFold(n_splits=k)\n",
    "    maes = []\n",
    "    for train_fold_index, validate_fold_index in kf.split(data):\n",
    "        train_fold = data[train_fold_index]\n",
    "        test_fold = data[validate_fold_index]\n",
    "        X_train_fold = train_fold[:, :-1]\n",
    "        Y_train_fold = train_fold[:, -1]\n",
    "        X_test_fold = test_fold[:, :-1]\n",
    "        Y_test_fold = test_fold[:, -1]\n",
    "        model.fit(X_train_fold, Y_train_fold)\n",
    "        Y_hat = model.predict(X_test_fold)\n",
    "        mae = np.mean([abs(Y_hat[i] - Y_test_fold[i]) for i in range(len(Y_test_fold))])\n",
    "        maes.append(mae)\n",
    "        print \"MAEs: \", maes\n",
    "    return np.mean(maes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make predictions on training data (using user median criteria)\n",
    "Y_hat = {}\n",
    "line_id = 1\n",
    "with open(train_file, 'r') as train_fh:\n",
    "    train_csv = csv.reader(train_fh, delimiter=',', quotechar='\"')\n",
    "    next(train_csv, None)\n",
    "    \n",
    "    for row in train_csv:\n",
    "        user = row[0]\n",
    "        artist = row[1]\n",
    "        \n",
    "        # modify this part if using different criteria\n",
    "        if user in user_medians:\n",
    "            Y_hat[line_id] = user_medians[user]\n",
    "        else:\n",
    "            break\n",
    "            print(\"User\", id, \"not in training data.\")\n",
    "            Y_hat[line_id] = global_median\n",
    "        line_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129.34241791969438"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([abs(Y_hat[i] - Y_actual[i]) for i in range(1, len(Y_hat))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# c = 0\n",
    "# for k, v in Y_hat.items():\n",
    "#     c += 1\n",
    "#     if (c > 8):\n",
    "#         break\n",
    "#     print(k)\n",
    "#     print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
