{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "import musicbrainzngs\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import csv\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Models\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# PCA and k-fold validation\n",
    "# from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fulltrain_file = '../musicrec-data/train.csv'\n",
    "ktrain_file = '../musicrec-data/ktrain.csv'\n",
    "kvalid_file = '../musicrec-data/kval.csv'\n",
    "\n",
    "# change this to reflect different solutions\n",
    "soln_file  = 'user_median.csv'\n",
    "\n",
    "# for full data, non kfold\n",
    "train_file = fulltrain_file\n",
    "test_file  = '../musicrec-data/test.csv'\n",
    "\n",
    "# for kfold validation\n",
    "train_file = ktrain_file\n",
    "test_file = kvalid_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4154804"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get length of fulltrain\n",
    "with open(fulltrain_file, 'r') as fulltrain_fh:\n",
    "    fulltrain_csv = csv.reader(fulltrain_fh, delimiter=',', quotechar='\"')\n",
    "    next(fulltrain_csv, None)\n",
    "    \n",
    "    data = list(fulltrain_csv)\n",
    "    rowsoftrain = len(data)\n",
    "rowsoftrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate fulltrain_file into training set and validation set (for kfold)\n",
    "c = 0\n",
    "with open(fulltrain_file, 'r') as fulltrain_fh:\n",
    "    fulltrain_csv = csv.reader(fulltrain_fh, delimiter=',', quotechar='\"')\n",
    "    next(fulltrain_csv, None)\n",
    "\n",
    "    with open(ktrain_file, 'w') as ktrain_fh:\n",
    "        ktrain_csv = csv.writer(ktrain_fh,\n",
    "                              delimiter=',',\n",
    "                              quotechar='\"',\n",
    "                              quoting=csv.QUOTE_MINIMAL)\n",
    "        \n",
    "        with open(kvalid_file, 'w') as kvalid_fh:\n",
    "            kvalid_csv = csv.writer(kvalid_fh,\n",
    "                                   delimiter=',',\n",
    "                                   quotechar='\"',\n",
    "                                   quoting=csv.QUOTE_MINIMAL)\n",
    "            \n",
    "            for row in fulltrain_csv:\n",
    "#                 user   = row[0]\n",
    "#                 artist = row[1]\n",
    "#                 plays  = row[2]\n",
    "#                 print(user, artist, plays)\n",
    "#                 assert(0 == 1)\n",
    "                if (c < (rowsoftrain * 4 / 5)):\n",
    "                    ktrain_csv.writerow(row)\n",
    "                else:\n",
    "                    kvalid_csv.writerow(row)\n",
    "                c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the training data.\n",
    "train_data = {}\n",
    "Y_actual = {} # for testing at end\n",
    "id = 1\n",
    "with open(train_file, 'r') as train_fh:\n",
    "    train_csv = csv.reader(train_fh, delimiter=',', quotechar='\"')\n",
    "    next(train_csv, None)\n",
    "    for row in train_csv:\n",
    "        user   = row[0]\n",
    "        artist = row[1]\n",
    "        plays  = int(row[2])\n",
    "        Y_actual[id] = plays\n",
    "        id += 1\n",
    "        if not user in train_data:\n",
    "            train_data[user] = {}\n",
    "        \n",
    "        train_data[user][artist] = plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# globalmedian.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global median: 118.0\n"
     ]
    }
   ],
   "source": [
    "# Predict via the median number of plays.\n",
    "\n",
    "# Compute the global median.\n",
    "plays_array = []\n",
    "for user, user_data in train_data.items():\n",
    "    for artist, plays in user_data.items():\n",
    "        plays_array.append(plays)\n",
    "global_median = np.median(np.array(plays_array))\n",
    "print(\"global median:\", global_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write out test solutions.\n",
    "Y_hat = {} # add this Y_hat line_id stuff to every solution\n",
    "line_id = 1\n",
    "with open(test_file, 'r') as test_fh:\n",
    "    test_csv = csv.reader(test_fh, delimiter=',', quotechar='\"')\n",
    "    next(test_csv, None)\n",
    "\n",
    "    with open(soln_file, 'w') as soln_fh:\n",
    "        soln_csv = csv.writer(soln_fh,\n",
    "                              delimiter=',',\n",
    "                              quotechar='\"',\n",
    "                              quoting=csv.QUOTE_MINIMAL)\n",
    "        soln_csv.writerow(['Id', 'plays'])\n",
    "\n",
    "        for row in test_csv:\n",
    "            id     = row[0]\n",
    "            user   = row[1]\n",
    "            artist = row[2]\n",
    "\n",
    "            soln_csv.writerow([id, global_median])\n",
    "            Y_hat[line_id] = global_median\n",
    "            line_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# usermedian.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict via the user-specific median.\n",
    "# If the user has no data, use the global median.\n",
    "\n",
    "# Compute the global median and per-user median.\n",
    "plays_array  = []\n",
    "user_medians = {}\n",
    "for user, user_data in train_data.items():\n",
    "    user_plays = []\n",
    "    for artist, plays in user_data.items():\n",
    "        plays_array.append(plays)\n",
    "        user_plays.append(plays)\n",
    "\n",
    "    user_medians[user] = np.median(np.array(user_plays))\n",
    "global_median = np.median(np.array(plays_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write out test solutions.\n",
    "Y_hat = {} # add this Y_hat line_id stuff to every solution\n",
    "line_id = 1\n",
    "with open(test_file, 'r') as test_fh:\n",
    "    test_csv = csv.reader(test_fh, delimiter=',', quotechar='\"')\n",
    "    next(test_csv, None)\n",
    "\n",
    "    with open(soln_file, 'w') as soln_fh:\n",
    "        soln_csv = csv.writer(soln_fh,\n",
    "                              delimiter=',',\n",
    "                              quotechar='\"',\n",
    "                              quoting=csv.QUOTE_MINIMAL)\n",
    "        soln_csv.writerow(['Id', 'plays'])\n",
    "\n",
    "        for row in test_csv:\n",
    "            id     = row[0]\n",
    "            user   = row[1]\n",
    "            artist = row[2]\n",
    "\n",
    "            if user in user_medians:\n",
    "                soln_csv.writerow([id, user_medians[user]])\n",
    "                Y_hat[line_id] = user_medians[user]\n",
    "            else:\n",
    "                print(\"User\", id, \"not in training data.\")\n",
    "                soln_csv.writerow([id, global_median])\n",
    "                Y_hat[line_id] = global_median\n",
    "            \n",
    "            line_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# must set user agent before any requests are made\n",
    "musicbrainzngs.set_useragent(1,1)\n",
    "# set user agent before any requests are made\n",
    "musicbrainzngs.set_useragent(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for getting the mode tag for an artist (alphabetical order)\n",
    "def mode_tag(artist_id):\n",
    "    result = musicbrainzngs.get_artist_by_id(artist_id,includes=['tags'])\n",
    "    tags = result['artist']['tag-list']\n",
    "    mode_tag = None\n",
    "    mode = None\n",
    "    for tag_dict in tags:\n",
    "        if tag_dict['count'] > mode:\n",
    "            mode = tag_dict['count']\n",
    "            mode_tag = tag_dict['name']\n",
    "    return mode_tag\n",
    "\n",
    "# mode_tag('a74b1b7f-71a5-4011-9441-d0b5e4122711')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in artist information\n",
    "artists = pd.read_csv('../musicrec-data/artists.csv', sep=',')\n",
    "artist_ids = artists['artist'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_artist_genre_dict(artists):\n",
    "    artist_genre_dict = {}\n",
    "    for artist_id in artists:\n",
    "        print artist_id\n",
    "        # update artist_genre dict\n",
    "        try: \n",
    "            genre = mode_tag(artist_id)\n",
    "            artist_genre_dict[artist_id] = genre\n",
    "        except (KeyError, musicbrainzngs.ResponseError):\n",
    "            artist_genre_dict[artist_id] = None\n",
    "    return artist_genre_dict\n",
    "            \n",
    "artist_genre_dict = build_artist_genre_dict(artist_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_user_genre_dict(train_data):\n",
    "    user_genre_dict = {}\n",
    "    for user, artist_info in train_data.iteritems():\n",
    "        print user\n",
    "        genre_dict = {}\n",
    "        for artist, plays in artist_info.iteritems():\n",
    "            genre = artist_genre_dict[artist]\n",
    "            # only proceed if genre is not None\n",
    "            if genre: \n",
    "                # if the user hasn't already listened to the genre\n",
    "                if genre not in genre_dict:\n",
    "                    genre_dict[genre] = (plays, 1)\n",
    "                # otherwise, add number of plays to current total\n",
    "                else:\n",
    "                    (num_genre_plays, num_genre_artists) = genre_dict[genre]\n",
    "                    genre_dict[genre] = (num_genre_plays + plays, num_genre_artists + 1)\n",
    "        user_genre_dict[user] = genre_dict\n",
    "    return user_genre_dict\n",
    "\n",
    "user_genre_dict = build_user_genre_dict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k,v in artist_genre_dict.iteritems():\n",
    "    print(k)\n",
    "    print(v)\n",
    "    break\n",
    "\n",
    "print(len(artist_genre_dict))\n",
    "\n",
    "for k,v in user_genre_dict.iteritems():\n",
    "    print(k)\n",
    "    print(v)\n",
    "    break\n",
    "    \n",
    "print(len(user_genre_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SAVE TO CSV\n",
    "with open('artist_genre_dict.csv', 'wb') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in artist_genre_dict.items():\n",
    "        if value:\n",
    "            writer.writerow([key, value.encode('ascii', 'ignore').decode('ascii')])\n",
    "        else:\n",
    "            writer.writerow([key, value])\n",
    "            \n",
    "# SAVE AS CSV\n",
    "with open('user_genre_dict.csv', 'wb') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in user_genre_dict.items():\n",
    "       writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist information, searching, and browsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'musicbrainzngs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d51074b56af6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmusicbrainzngs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_artists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"radiohead\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#musicbrainzngs.search_recordings(\"bennie and the jets\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mradiohead_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"a74b1b7f-71a5-4011-9441-d0b5e4122711\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mradiohead_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmusicbrainzngs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_artist_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mradiohead_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mincludes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"releases\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"ratings\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'musicbrainzngs' is not defined"
     ]
    }
   ],
   "source": [
    "musicbrainzngs.search_artists(\"radiohead\")\n",
    "#musicbrainzngs.search_recordings(\"bennie and the jets\")\n",
    "\n",
    "radiohead_id = \"a74b1b7f-71a5-4011-9441-d0b5e4122711\"\n",
    "radiohead_result = musicbrainzngs.get_artist_by_id(radiohead_id,includes=[\"releases\",\"ratings\"])\n",
    "radiohead_artist = radiohead_result[\"artist\"]\n",
    "\n",
    "print(\"name:\\t\\t%s\" % radiohead_artist[\"name\"])\n",
    "print(\"rating:\\t\\t%s\" % radiohead_artist[\"rating\"])\n",
    "print(\"release 0:\\t%s\" % radiohead_artist[\"release-list\"][0])\n",
    "\n",
    "# dictionary of recordings for radiohead\n",
    "# musicbrainzngs.browse_recordings(radiohead_id)\n",
    "\n",
    "# \"artist\" can include the following information:\n",
    "# recordings, releases, release-groups, works, various-artists,\n",
    "# discids, media, isrcs, aliases, annotation, area-rels, artist-rels,\n",
    "# label-rels, place-rels, event-rels, recording-rels, release-rels,\n",
    "# release-group-rels, series-rels, url-rels, work-rels, instrument-rels,\n",
    "# tags, user-tags, ratings, user-ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cover art information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'images': [{u'approved': True,\n",
       "   u'back': False,\n",
       "   u'comment': u'',\n",
       "   u'edit': 35299266,\n",
       "   u'front': True,\n",
       "   u'id': 11628918400,\n",
       "   u'image': u'http://coverartarchive.org/release/081e7033-5282-4bd7-9963-e64edf8c693a/11628918400.jpg',\n",
       "   u'thumbnails': {u'large': u'http://coverartarchive.org/release/081e7033-5282-4bd7-9963-e64edf8c693a/11628918400-500.jpg',\n",
       "    u'small': u'http://coverartarchive.org/release/081e7033-5282-4bd7-9963-e64edf8c693a/11628918400-250.jpg'},\n",
       "   u'types': [u'Front']}],\n",
       " u'release': u'https://musicbrainz.org/release/081e7033-5282-4bd7-9963-e64edf8c693a'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets the list of cover art associated with a release\n",
    "musicbrainzngs.get_image_list(\"081e7033-5282-4bd7-9963-e64edf8c693a\")\n",
    "\n",
    "# downloads the front cover art of a release\n",
    "# musicbrainzngs.get_image_front(\"081e7033-5282-4bd7-9963-e64edf8c693a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for k-fold cross validation using MAE (mean absolute error)\n",
    "def kfold(k, model, data):\n",
    "    kf = KFold(n_splits=k)\n",
    "    maes = []\n",
    "    for train_fold_index, validate_fold_index in kf.split(data):\n",
    "        train_fold = data[train_fold_index]\n",
    "        test_fold = data[validate_fold_index]\n",
    "        X_train_fold = train_fold[:, :-1]\n",
    "        Y_train_fold = train_fold[:, -1]\n",
    "        X_test_fold = test_fold[:, :-1]\n",
    "        Y_test_fold = test_fold[:, -1]\n",
    "        model.fit(X_train_fold, Y_train_fold)\n",
    "        Y_hat = model.predict(X_test_fold)\n",
    "        mae = np.mean([abs(Y_hat[i] - Y_test_fold[i]) for i in range(len(Y_test_fold))])\n",
    "        maes.append(mae)\n",
    "        print \"MAEs: \", maes\n",
    "    return np.mean(maes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For kfold: make predictions on partial training data (using user median criteria)\n",
    "Y_hat = {}\n",
    "line_id = 1\n",
    "with open(train_file, 'r') as train_fh:\n",
    "    train_csv = csv.reader(train_fh, delimiter=',', quotechar='\"')\n",
    "    next(train_csv, None)\n",
    "    \n",
    "    for row in train_csv:\n",
    "        user = row[0]\n",
    "        artist = row[1]\n",
    "        \n",
    "        # modify this part if using different criteria\n",
    "        if user in user_medians:\n",
    "            Y_hat[line_id] = user_medians[user]\n",
    "        else:\n",
    "            break\n",
    "            print(\"User\", id, \"not in training data.\")\n",
    "            Y_hat[line_id] = global_median\n",
    "        line_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129.34241791969438"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([abs(Y_hat[i] - Y_actual[i]) for i in range(1, len(Y_hat))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# c = 0\n",
    "# for k, v in Y_hat.items():\n",
    "#     c += 1\n",
    "#     if (c > 8):\n",
    "#         break\n",
    "#     print(k)\n",
    "#     print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
